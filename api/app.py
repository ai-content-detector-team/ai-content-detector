#===========================================
#========== IMPORT DES LIBRAIRIES ==========
#===========================================

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import Union



#===================================================
#========== DESCRIPTION COMPLETE DE L'API ==========
#===================================================

description = """
## AI Review Detector API

L'**AI Review Detector API** est une solution professionnelle de d√©tection automatique des avis g√©n√©r√©s par intelligence artificielle.

### üéØ Objectif

Cette API permet d'identifier si un avis client ou une critique a √©t√© r√©dig√© par un humain ou g√©n√©r√© par une intelligence artificielle, 
aidant ainsi les entreprises √† maintenir l'authenticit√© de leurs plateformes d'√©valuation.

### üî¨ Mod√®le de d√©tection

Notre syst√®me repose sur un mod√®le **XGBoost** entra√Æn√© sur un vaste corpus de textes authentiques et g√©n√©r√©s par IA.

**Performances du mod√®le sur de nouvelles donn√©es :**
- **Accuracy** : XX.XX%
- **Precision** : XX.XX%
- **Recall** : XX.XX%
- **F1-Score** : XX.XX%

**Dataset d'entra√Ænement :**
- XXX avis √©tiquet√©s (XXX humains / XXX IA)
- Source : Kaggle (liens vers les datasets)
- Langue : Anglais (uniquement, non?)
- Taille variable : De courts commentaires √† des essais d√©taill√©s

### üí° Cas d'usage

- **E-commerce** : Validation de l'authenticit√© des avis produits
- **H√¥tellerie** : D√©tection de faux avis sur les plateformes de r√©servation  
- **Mod√©ration** : Filtrage automatique des contenus g√©n√©r√©s automatiquement par IA
- **Analyse qualitative** : Audit de bases de donn√©es d'avis existantes

### üöÄ Fonctionnalit√©s

Cette API propose deux modes d'utilisation :

1. **Analyse unitaire** : D√©tection pour un seul texte
2. **Traitement par lot** : Analyse de jusqu'√† 10,000 textes simultan√©ment pour un traitement efficace

### üìä Format des donn√©es

**Entr√©e :** Texte brut (sans limite de longueur)  
**Sortie :** Classification binaire (1 = IA ou 0 = Humain)

### ‚ö° Performance

Temps de r√©ponse moyen : < XXXms par texte
"""

app = FastAPI(
    title="AI Review Detector API",
    description=description,
    version="1.0.0",
    contact={
        "name": "AI Review Detector Team",
        "email": "contact@aireviewdetector.com",
    }
)



#=========================================
# ========== MODELES DE DONNEES ==========
#=========================================

#Mod√®le de donn√©es pour une requ√™te unitaire
class TextInput(BaseModel):
    text: str = Field(
        ...,
        description="Texte de l'avis √† analyser",
        example="This product exceeded my expectations! The quality is outstanding and delivery was super fast"
    )

#Mod√®le de donn√©es pour une requ√™te batch
class BatchTextInput(BaseModel):
    texts: Union[list[str], list[dict]] = Field(
        ...,
        description="Liste de textes √† analyser (maximum 10,000)",
        max_length=10000,
        example=[
            "This product exceeded my expectations! The quality is outstanding.",
            {"text": "I really enjoyed my stay at this hotel. The staff was very friendly."},
            "The food was delicious and the service was impeccable."
        ]
    )

#Mod√®le de donn√©es pour une r√©ponse unitaire
class PredictionResponse(BaseModel):
    is_ai_generated: int = Field(..., description="1 si g√©n√©r√© par l'IA, 0 si √©crit par un humain")
    message: str = Field(..., description="Message explicatif du r√©sultat")

#Mod√®le de donn√©es pour une r√©ponse batch
class BatchPredictionResponse(BaseModel):
    predictions: list[int] = Field(..., description="Liste des pr√©dictions (1 = IA, 0 = Humain)")



#===============================================
#========== FONCTION DE PREPROCESSING ==========
#===============================================

def preprocessor(text):
    """
    Pr√©traite le texte et extrait les features n√©cessaires au mod√®le.
    """
    features = "Ecrire le preprocessing"
    return features



#====================================================
#========== IMPORT DU MODELE DE PREDICTION ==========
#====================================================

model = "IMPORTER LE MODELE DEPUIS MLFLOW"



#=========================================
#=============== ENDPOINTS ===============
#=========================================

@app.get("/", tags=["Root"])
async def root():
    """
    Point d'entr√©e de l'API.
    
    Retourne les informations de base sur le service.
    """
    return "Retrouvez toute la documentation de l'API sur /docs"


@app.post("/predict", response_model=PredictionResponse, tags=["D√©tection"])
async def predict_single_text(input_data: TextInput):
    """
    Analyse un seul texte pour d√©termin√© s'il a √©t√© g√©n√©r√© par une IA.

    **Retourne :**
    - `is_ai_generated` : 1 si le texte est g√©n√©r√© par IA, 0 s'il est √©crit par un humain
    - `message` : Message explicatif en langage naturel
    """

    #Preprocessing
    features = preprocessor(input_data.text)

    #Pr√©diction
    prediction = model.predict(features)

    #Message explicatif
    if prediction == 1:
        message = "Cet avis semble avoir √©t√© g√©n√©r√© par une intelligence artificielle."
    else:
        message = "Ce texte semble avoir √©t√© √©crit par un humain."

    return PredictionResponse(
        is_ai_generated=prediction,
        message=message
    )


@app.post("/predict-batch", response_model=BatchPredictionResponse, tags=["D√©tection"])
async def predict_batch_texts(input_data: BatchTextInput):
    """
    Analyse plusieurs textes simultan√©ment pour d√©terminer s'ils ont √©t√© g√©n√©r√©s par une IA.

    **Limite :** Maximum 10,000 textes par requ√™te

    **Formats accept√©s :**
    - Liste de strings: `["text1", "text2", ...]`

    - Liste de dictionnaires: `[{"text": "text1}, {"texte": "text2}, ...]`

    **Retourne :**
    `predictions` : Liste des pr√©dictions (1 = IA, 0 = Humain) dans le m√™me ordre que les textes soumis
    """

    #Extraction des textes selon le format
    texts = []
    for item in input_data.texts:
        #Si c'est une liste de textes
        if isinstance(item, str):
            texts.append(item)
        #Sinon, si c'est une liste de dictionnaire
        elif isinstance(item, dict):
            #Et si ce dictionnaire contient une cl√© "text"
            if "text" in item:
                texts.append(item["text"])
            #Ou sinon si ce dictionnaire contient une cl√© "texte"
            elif "texte" in item:
                texts.append(item['texte'])
            #Sinon, on l√®ve une erreur
            else:
                raise HTTPException(
                    status_code=400,
                    detail="Les dictionnaires doivent contenir une cl√© 'texte."
                )
        #Si ce n'est ni une liste de texte ni une liste de dictionnaire, on l√®ve une erreur
        else:
            raise HTTPException(
                statsu_code=400,
                detail=f"Format non support√©: {type(item)}. Utilisez des strings ou des dictionnaires."
            )

    #Preprocessing
    features_list = [preprocessor(text) for text in texts]

    #Predictions
    predictions = model.predict(features_list)

    #Conversion en liste
    predictions = predictions.tolist() if hasattr(predictions, 'tolist  ') else list(predictions)

    return BatchPredictionResponse(predictions=predictions)